{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69efc36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4521d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup the model\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c552bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a chatHistory list to store the chat history\n",
    "chatHistory = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e5d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Chatbot! Type 'exit' to quit.\n",
      "bot: Hello! How can I assist you today?\n",
      "Exiting the chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 3. creating terminal based infinite chat\n",
    "print(\"Welcome to the Chatbot! Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    chatHistory.append(user_input)\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Exiting the chatbot. Goodbye!\")\n",
    "        break\n",
    "    response = model.invoke(chatHistory)\n",
    "    chatHistory.append(response.content)    \n",
    "    print(\"bot:\", response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6397fdb",
   "metadata": {},
   "source": [
    "The `invoke` function is highly versatile and powerful. It can handle both:\n",
    "\n",
    "1. **Single Prompt**: You can pass a single string as input, and the model will generate a response based on that prompt.\n",
    "2. **List of Statements**: You can also pass a list of statements (e.g., a conversation history), and the model will generate a response considering the context provided by the entire list.\n",
    "\n",
    "This flexibility makes it suitable for both simple queries and complex conversational workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e849fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History: ['hi', 'Hello! How can I assist you today?', 'exit']\n"
     ]
    }
   ],
   "source": [
    "## lets check our chat history\n",
    "print(\"Chat History:\", chatHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba15974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## so you can see the chat history is stored in the chatHistory list    \n",
    "# but there is problem, the chat history has no context of who said what\n",
    "# if the chat history is long it will be hard to understand who said what\n",
    "# to fix it we will implement dictionary instead of list\n",
    "# and we will use the message library from langchain to store the chat history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4736af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Chatbot! Type 'exit' to quit.\n",
      "bot: Hello! How can I help you today?\n",
      "Exiting the chatbot. Goodbye!\n",
      "system: You are a helpful chat assistant.\n",
      "human: hi\n",
      "ai: Hello! How can I help you today?\n",
      "human: exit\n"
     ]
    }
   ],
   "source": [
    "chatHistory = [\n",
    "    SystemMessage(content=\"You are a helpful chat assistant.\"),\n",
    "]\n",
    "\n",
    "print(\"Welcome to the Chatbot! Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    chatHistory.append(HumanMessage(content=user_input))\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Exiting the chatbot. Goodbye!\")\n",
    "        break\n",
    "    response = model.invoke(chatHistory)\n",
    "    chatHistory.append(AIMessage(content=response.content))\n",
    "    print(\"bot:\", response.content)\n",
    "\n",
    "## lets check our chat history\n",
    "for message in chatHistory:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8b6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now no matter how long the chat history is , the llm can easily understand who said what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d8d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genai)",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
